{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# OpenCV Eigenfaces for Face Recognition"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is base on the course from Adrian Rosebrock from PyImageSearch. The original post can be found [here](https://pyimagesearch.com/2021/05/10/opencv-eigenfaces-for-face-recognition/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage.exposure import rescale_intensity\n",
        "from matplotlib import pyplot as plt\n",
        "from imutils import build_montages, paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_face_data(path=\"./FacePhotosCleaned\"):\n",
        "    \"\"\"Function to load the face dataset and return the cropped faces and labels\"\"\"\n",
        "    faces = []\n",
        "    labels = []\n",
        "    for file in os.listdir(path):\n",
        "        img = cv2.imread(path + \"/\" + file)\n",
        "        img = cv2.resize(img, (200, 200))\n",
        "        faces.append(img)\n",
        "        labels.append(file.split(\".\")[0]) # get the name of the person from the file name\n",
        "    return faces, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Implementing Eigenfaces with OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6s/16s1gbw10hv5zn6phb0s3b480000gn/T/ipykernel_55094/337928052.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  pcaFaces = np.array([f.flatten() for f in faces])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'# construct our training and testing split\\nsplit = train_test_split(faces, pcaFaces, labels, test_size=0.25,\\n\\tstratify=labels, random_state=42)\\n(origTrain, origTest, trainX, testX, trainY, testY) = split'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "(faces, labels) = load_face_data(\"/Users/diegosanmartin/Downloads/Computer Vision/FaceRecognition/FacePhotosCleaned\")\n",
        "\n",
        "# flatten all 2D faces into a 1D list of pixel intensities\n",
        "pcaFaces = np.array([f.flatten() for f in faces])\n",
        "\n",
        "# encode the string labels as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "\"\"\"# construct our training and testing split\n",
        "split = train_test_split(faces, pcaFaces, labels, test_size=0.25,\n",
        "\tstratify=labels, random_state=42)\n",
        "(origTrain, origTest, trainX, testX, trainY, testY) = split\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1442826\n",
            "1140216\n",
            "1963443\n",
            "4082166\n",
            "1096260\n",
            "369603\n",
            "2713203\n",
            "594075\n",
            "230187\n",
            "453963\n",
            "1474203\n",
            "4969107\n",
            "390963\n",
            "892710\n",
            "73947\n",
            "175692\n",
            "153228\n",
            "578163\n",
            "463347\n",
            "7004352\n",
            "2389668\n",
            "4884528\n",
            "157323\n",
            "184512\n",
            "297675\n",
            "127308\n"
          ]
        }
      ],
      "source": [
        "for face in pcaFaces:\n",
        "    print(len(face))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "u8jwi2Jg_B7F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] creating eigenfaces...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m pca \u001b[39m=\u001b[39m PCA(\n\u001b[1;32m      5\u001b[0m \tsvd_solver\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m \tn_components\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m,\n\u001b[1;32m      7\u001b[0m \twhiten\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m trainX \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(pcaFaces)\n\u001b[1;32m     10\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] computing eigenfaces took \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     12\u001b[0m \tend \u001b[39m-\u001b[39m start))\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    487\u001b[0m )\n\u001b[1;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[0;32m~/Downloads/Computer Vision/venv/lib/python3.8/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ],
      "source": [
        "# compute the PCA (eigenfaces) representation of the data, then\n",
        "# project the training data onto the eigenfaces subspace\n",
        "print(\"[INFO] creating eigenfaces...\")\n",
        "pca = PCA(\n",
        "\tsvd_solver=\"randomized\",\n",
        "\tn_components=150,\n",
        "\twhiten=True)\n",
        "start = time.time()\n",
        "trainX = pca.fit_transform(pcaFaces)\n",
        "end = time.time()\n",
        "print(\"[INFO] computing eigenfaces took {:.4f} seconds\".format(\n",
        "\tend - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8cCSeNO_GFQ"
      },
      "outputs": [],
      "source": [
        "# check to see if the PCA components should be visualized\n",
        "if args[\"visualize\"] > 0:\n",
        "\t# initialize the list of images in the montage\n",
        "\timages = []\n",
        "\n",
        "\t# loop over the first 16 individual components\n",
        "\tfor (i, component) in enumerate(pca.components_[:16]):\n",
        "\t\t# reshape the component to a 2D matrix, then convert the data\n",
        "\t\t# type to an unsigned 8-bit integer so it can be displayed\n",
        "\t\t# with OpenCV\n",
        "\t\tcomponent = component.reshape((62, 47))\n",
        "\t\tcomponent = rescale_intensity(component, out_range=(0, 255))\n",
        "\t\tcomponent = np.dstack([component.astype(\"uint8\")] * 3)\n",
        "\t\timages.append(component)\n",
        "\n",
        "\t# construct the montage for the images\n",
        "\tmontage = build_montages(images, (47, 62), (4, 4))[0]\n",
        "\n",
        "\t# show the mean and principal component visualizations\n",
        "\t# show the mean image\n",
        "\tmean = pca.mean_.reshape((62, 47))\n",
        "\tmean = rescale_intensity(mean, out_range=(0, 255)).astype(\"uint8\")\n",
        "\tplt_imshow(\"Mean\", mean)\n",
        "\tplt_imshow(\"Components\", montage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7chGsGuT_HhH"
      },
      "outputs": [],
      "source": [
        "# train a classifier on the eigenfaces representation\n",
        "print(\"[INFO] training classifier...\")\n",
        "model = SVC(kernel=\"rbf\", C=10.0, gamma=0.001, random_state=42)\n",
        "model.fit(trainX, trainY)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"[INFO] evaluating model...\")\n",
        "predictions = model.predict(pca.transform(testX))\n",
        "print(classification_report(testY, predictions,\n",
        "\ttarget_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG1VHjHz_KUp"
      },
      "outputs": [],
      "source": [
        "# generate a sample of testing data\n",
        "idxs = np.random.choice(range(0, len(testY)), size=10, replace=False)\n",
        "\n",
        "# loop over a sample of the testing data\n",
        "for i in idxs:\n",
        "\t# grab the predicted name and actual name\n",
        "\tpredName = le.inverse_transform([predictions[i]])[0]\n",
        "\tactualName = le.classes_[testY[i]]\n",
        "\n",
        "\t# grab the face image and resize it such that we can easily see\n",
        "\t# it on our screen\n",
        "\tface = np.dstack([origTest[i]] * 3)\n",
        "\tface = imutils.resize(face, width=250)\n",
        "\n",
        "\t# draw the predicted name and actual name on the image\n",
        "\tcv2.putText(face, \"pred: {}\".format(predName), (5, 25),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\tcv2.putText(face, \"actual: {}\".format(actualName), (5, 60),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "\t# display the predicted name  and actual name\n",
        "\tprint(\"[INFO] prediction: {}, actual: {}\".format(\n",
        "\t\tpredName, actualName))\n",
        "\n",
        "\t# display the current face to our screen\n",
        "\tplt_imshow(\"Face\", face)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*OpenCV Eigenfaces for Face Recognition*](https://www.pyimagesearch.com/2021/05/10/opencv-eigenfaces-for-face-recognition/) published on 2021-05-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sef8alx4cGYc"
      },
      "source": [
        "# Code License Agreement\n",
        "```\n",
        "Copyright (c) 2021 PyImageSearch.com\n",
        "\n",
        "SIMPLE VERSION\n",
        "Feel free to use this code for your own projects, whether they are\n",
        "purely educational, for fun, or for profit. THE EXCEPTION BEING if\n",
        "you are developing a course, book, or other educational product.\n",
        "Under *NO CIRCUMSTANCE* may you use this code for your own paid\n",
        "educational or self-promotional ventures without written consent\n",
        "from Adrian Rosebrock and PyImageSearch.com.\n",
        "\n",
        "LONGER, FORMAL VERSION\n",
        "Permission is hereby granted, free of charge, to any person obtaining\n",
        "a copy of this software and associated documentation files\n",
        "(the \"Software\"), to deal in the Software without restriction,\n",
        "including without limitation the rights to use, copy, modify, merge,\n",
        "publish, distribute, sublicense, and/or sell copies of the Software,\n",
        "and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be\n",
        "included in all copies or substantial portions of the Software.\n",
        "Notwithstanding the foregoing, you may not use, copy, modify, merge,\n",
        "publish, distribute, sublicense, create a derivative work, and/or\n",
        "sell copies of the Software in any work that is designed, intended,\n",
        "or marketed for pedagogical or instructional purposes related to\n",
        "programming, coding, application development, or information\n",
        "technology. Permission for such use, copying, modification, and\n",
        "merger, publication, distribution, sub-licensing, creation of\n",
        "derivative works, or sale is expressly withheld.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
        "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
        "OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
        "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n",
        "BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n",
        "ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "1903-opencv_eigenfaces.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
